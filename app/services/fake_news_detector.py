import asyncio
import openai
from typing import List, Dict, Any, Optional
import logging
import json
import re
import base64
from datetime import datetime
try:
    from ..data_models.detection_result import FakeNewsDetectionResult
except ImportError:
    # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    import os
    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå½“å‰æ–‡ä»¶çš„ä¸Šä¸Šçº§ç›®å½•ï¼‰
    current_dir = os.path.dirname(__file__)  # servicesç›®å½•
    parent_dir = os.path.dirname(current_dir)  # appç›®å½•  
    project_root = os.path.dirname(parent_dir)  # é¡¹ç›®æ ¹ç›®å½•
    sys.path.insert(0, project_root)
    from app.data_models.detection_result import FakeNewsDetectionResult

logger = logging.getLogger(__name__)


class FakeNewsDetector:
    """è™šå‡ä¿¡æ¯æ£€æµ‹æœåŠ¡"""
    
    def __init__(self, openai_api_key: str, model_name: str = "gpt-4o"):  # é»˜è®¤ä½¿ç”¨å¤šæ¨¡æ€æ¨¡å‹
        self.client = openai.AsyncOpenAI(api_key=openai_api_key)
        self.model_name = model_name
        
        # è™šå‡ä¿¡æ¯æ£€æµ‹çš„ç³»ç»Ÿæç¤ºè¯
        # ä»app/prompts/fake_news_detection_prompt.txtä¸­è¯»å–
        try:
            with open('app/prompts/fake_news_detection_prompt.txt', 'r', encoding='utf-8') as file:
                self.system_prompt = file.read()
        except FileNotFoundError:
            # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç›¸å¯¹äºå½“å‰æ–‡ä»¶çš„è·¯å¾„
            import os
            current_dir = os.path.dirname(__file__)
            prompt_path = os.path.join(os.path.dirname(current_dir), 'prompts', 'fake_news_detection_prompt.txt')
            with open(prompt_path, 'r', encoding='utf-8') as file:
                self.system_prompt = file.read()
    
    async def detect_fake_news(
        self, 
        content: str, 
        user_id: Optional[str] = None,
        images: Optional[List[str]] = None
    ) -> FakeNewsDetectionResult:
        """æ£€æµ‹è™šå‡ä¿¡æ¯ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼šæ–‡æœ¬+å›¾åƒï¼‰"""
        max_tries = 5
        last_error = None
        
        for attempt in range(max_tries):
            try:
                logger.info(f"è™šå‡ä¿¡æ¯æ£€æµ‹å°è¯• {attempt + 1}/{max_tries}")
                
                # ä½¿ç”¨LLMè¿›è¡Œè¯¦ç»†åˆ†æï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
                analysis_result = await self._analyze_content_with_llm_multimodal(
                    content, images
                )
                
                # å…¼å®¹æ–°æ—§å­—æ®µ
                is_fake = analysis_result.get("is_fake_news", analysis_result.get("is_fake", False))
                
                return FakeNewsDetectionResult(
                    result_id=self._generate_result_id(),
                    content_text=content,
                    is_detected=is_fake,
                    confidence_score=analysis_result.get("confidence", 0.0),
                    reasons=analysis_result.get("fake_aspects", analysis_result.get("reasons", [])),
                    evidence=analysis_result.get("false_claims", analysis_result.get("evidence", [])),
                    user_id=user_id,
                    fact_check_sources=analysis_result.get("safety_tips", analysis_result.get("fact_check_suggestions", [])),
                    
                    # æ–°å¢å­—æ®µ
                    is_fake_for_elderly=is_fake,
                    fake_aspects=analysis_result.get("fake_aspects", []),
                    false_claims=analysis_result.get("false_claims", []),
                    factual_version=analysis_result.get("factual_version", ""),
                    truth_explanation=analysis_result.get("truth_explanation", ""),
                    safety_tips=analysis_result.get("safety_tips", [])
                )
                
            except Exception as e:
                last_error = e
                logger.warning(f"è™šå‡ä¿¡æ¯æ£€æµ‹ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt < max_tries - 1:
                    await asyncio.sleep(1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    
        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        logger.error(f"è™šå‡ä¿¡æ¯æ£€æµ‹å¤±è´¥ï¼Œå·²å°è¯•{max_tries}æ¬¡: {last_error}")
        return self._create_error_result(content, user_id, str(last_error))

    async def _analyze_content_with_llm_multimodal(
        self, 
        content: str, 
        images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹åˆ†æå†…å®¹"""
        try:
            # é™åˆ¶æ–‡æœ¬å†…å®¹é•¿åº¦
            if len(content) > 2000:
                content = content[:2000] + "..."
            
            user_prompt = f"è¯·åˆ†æä»¥ä¸‹å†…å®¹æ˜¯å¦åŒ…å«è™šå‡ä¿¡æ¯ã€è°£è¨€æˆ–è¯ˆéª—å†…å®¹ï¼š\n\næ–‡æœ¬å†…å®¹ï¼š\n{content}"
            
            # å¦‚æœæœ‰å›¾åƒï¼Œæ·»åŠ è¯´æ˜
            if images and len(images) > 0:
                user_prompt += f"\n\nå›¾åƒæ•°é‡ï¼š{len(images)}å¼ ï¼Œè¯·ç»“åˆå›¾åƒå†…å®¹è¿›è¡Œåˆ†æ"
            
            user_prompt += "\n\nè¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"
            
            # æ„å»ºmessagesï¼Œæ”¯æŒå›¾åƒè¾“å…¥
            messages = [
                {"role": "system", "content": self.system_prompt}
            ]
            
            # ç”¨æˆ·æ¶ˆæ¯åŒ…å«æ–‡æœ¬å’Œå›¾åƒ
            user_message = {"role": "user", "content": []}
            
            # æ·»åŠ æ–‡æœ¬å†…å®¹
            user_message["content"].append({
                "type": "text",
                "text": user_prompt
            })
            
            # æ·»åŠ å›¾åƒï¼ˆæœ€å¤š5å¼ ï¼‰
            if images:
                image_count = min(len(images), 5)
                for i, image_path in enumerate(images[:image_count]):
                    try:
                        with open(image_path, "rb") as image_file:
                            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
                        
                        user_message["content"].append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{base64_image}"
                            }
                        })
                    except Exception as e:
                        logger.warning(f"æ— æ³•è¯»å–å›¾åƒ {image_path}: {e}")
            
            messages.append(user_message)
            
            response = await self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=0.1,
                max_tokens=1000
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # å°è¯•è§£æJSONç»“æœ
            try:
                json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                if json_match:
                    result_json = json.loads(json_match.group())
                else:
                    result_json = json.loads(result_text)
                
                return result_json
                
            except json.JSONDecodeError:
                logger.warning(f"LLMè¿”å›ç»“æœä¸æ˜¯æœ‰æ•ˆJSON: {result_text}")
                return self._get_default_llm_result()
                
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€LLMåˆ†æå¤±è´¥: {e}")
            return self._get_default_llm_result()
    
    def _get_default_llm_result(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤çš„LLMç»“æœ"""
        return {
            "is_fake_news": False,
            "confidence": 0.0,
            "fake_aspects": ["ç³»ç»Ÿæ— æ³•æ­£å¸¸åˆ†æå†…å®¹"],
            "false_claims": [],
            "risk_level": "ä½é£é™©",
            "factual_version": "å†…å®¹çš„çœŸå®æ€§æš‚æ—¶æ— æ³•ç¡®å®š",
            "truth_explanation": "æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶æ— æ³•åˆ†æè¿™æ®µå†…å®¹ï¼Œå»ºè®®æ‚¨å‘æƒå¨æœºæ„æˆ–ä¸“ä¸šäººå£«å’¨è¯¢ã€‚",
            "safety_tips": ["é‡åˆ°ä¸ç¡®å®šçš„ä¿¡æ¯ï¼Œå¯ä»¥å‘å®¶äººæˆ–æœ‹å‹è¯¢é—®", "å¯ä»¥æŸ¥çœ‹å®˜æ–¹åª’ä½“çš„ç›¸å…³æŠ¥é“"]
        }
    
    def _generate_result_id(self) -> str:
        """ç”Ÿæˆç»“æœID"""
        return f"fake_news_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
    
    def _create_error_result(self, content: str, user_id: Optional[str], 
                            error_msg: str) -> FakeNewsDetectionResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return FakeNewsDetectionResult(
            result_id=self._generate_result_id(),
            content_text=content,
            is_detected=False,
            confidence_score=0.0,
            reasons=[f"æ£€æµ‹å¤±è´¥: {error_msg}"],
            evidence=[],
            user_id=user_id,
            fact_check_sources=[],
            
            # æ–°å¢å­—æ®µ
            is_fake_for_elderly=False,
            fake_aspects=[f"æ£€æµ‹å¤±è´¥: {error_msg}"],
            false_claims=[],
            factual_version="ç”±äºç³»ç»Ÿé”™è¯¯ï¼Œæ— æ³•æä¾›å‡†ç¡®ä¿¡æ¯",
            truth_explanation="ç³»ç»Ÿé‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼Œæ— æ³•å®Œæˆåˆ†æã€‚å»ºè®®æ‚¨ç¨åé‡è¯•æˆ–å’¨è¯¢ä¸“ä¸šäººå£«ã€‚",
            safety_tips=["é‡åˆ°æŠ€æœ¯é—®é¢˜æ—¶ï¼Œå¯ä»¥ç¨åé‡è¯•", "é‡è¦ä¿¡æ¯å»ºè®®å¤šæ–¹æ±‚è¯"]
        )

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('fake_news_test.log', encoding='utf-8'),  # è¾“å‡ºåˆ°æ–‡ä»¶
            logging.StreamHandler()  # è¾“å‡ºåˆ°æ§åˆ¶å°
        ]
    )
    
    import asyncio
    from app.services.content_crawler import ContentCrawler
    
    async def test_detector():
        import os
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            print("é”™è¯¯: æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡åå†è¿è¡Œæµ‹è¯•")
            return
        detector = FakeNewsDetector(openai_api_key)
        crawler = ContentCrawler()
        douyin_content=crawler.process_douyin_content("https://www.iesdouyin.com/share/video/7510767099883867451/?region=CN&mid=7295817689289033738&u_code=174jbch63&did=MS4wLjABAAAAiI9AU35XILhOstht_K9TXNs_-ytW9mzHedcet48iSllA0s2OKl8r1cuJ3KqUh5Wj&iid=MS4wLjABAAAAMyVVHT8VSTilkC1aQjuNrjTTxeAR8ebw6XpfjCjWe60jlQ9gngEd8sBMgz7AqZ9x&with_sec_did=1&video_share_track_ver=&titleType=title&share_sign=7JQ.V8p.qvEOo1eXmZy5cWecgS6Cpv_QDhjHUaRGuqs-&share_version=340000&ts=1748786999&from_aid=1128&from_ssr=1&utm_source=copy&utm_campaign=client_share&utm_medium=android&app=aweme&activity_info=%7B%22social_author_id%22%3A%223959768795851737%22%2C%22social_share_id%22%3A%22102862430872_1748787023100%22%2C%22social_share_time%22%3A%221748787023%22%2C%22social_share_user_id%22%3A%22102862430872%22%7D&share_extra_params=%7B%22schema_type%22%3A%221%22%7D")
        
        result = await detector.detect_fake_news(content = douyin_content["transcript"], images = douyin_content["frames"])        
        print(f"ğŸ” åŸå§‹ä¿¡æ¯: {result}")
        print(f"ğŸ“± æ˜¯å¦ä¸ºè™šå‡ä¿¡æ¯: {'æ˜¯' if result.is_detected else 'å¦'}")
        print(f"ğŸ¯ ç¡®ä¿¡ç¨‹åº¦: {result.confidence_score:.1%}")
        
        if result.is_detected:
            print(f"âš ï¸  é£é™©ç­‰çº§: {getattr(result, 'risk_level', 'æœªçŸ¥')}")
            
            print(f"\nâ“ è™šå‡æ–¹é¢:")
            for aspect in result.fake_aspects or []:
                print(f"   â€¢ {aspect}")
            
            print(f"\nğŸš« è™šå‡å£°ç§°:")
            for claim in result.false_claims or []:
                print(f"   â€¢ {claim}")
            
            print(f"\nâœ¨ çœŸå®ä¿¡æ¯ç‰ˆæœ¬:")
            print(f"   {result.factual_version}")
        else:
            print(f"âœ… ä¿¡æ¯å¯ä¿¡ï¼Œæ— éœ€çº æ­£")
        
        print(f"\nğŸ’¬ ç»™è€å¹´äººçš„è§£é‡Š:")
        print(f"   {result.truth_explanation}")
        
        if result.safety_tips:
            print(f"\nğŸ’¡ é˜²éª—æé†’:")
            for tip in result.safety_tips:
                print(f"   â€¢ {tip}")
    
    asyncio.run(test_detector()) 