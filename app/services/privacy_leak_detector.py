import asyncio
import dashscope
import re
from typing import List, Dict, Any, Optional
import logging
import json
import base64
from datetime import datetime

try:
    from ..data_models.detection_result import PrivacyLeakDetectionResult
except ImportError:
    # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    import sys
    import os
    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå½“å‰æ–‡ä»¶çš„ä¸Šä¸Šçº§ç›®å½•ï¼‰
    current_dir = os.path.dirname(__file__)  # servicesç›®å½•
    parent_dir = os.path.dirname(current_dir)  # appç›®å½•  
    project_root = os.path.dirname(parent_dir)  # é¡¹ç›®æ ¹ç›®å½•
    sys.path.insert(0, project_root)
    from app.data_models.detection_result import PrivacyLeakDetectionResult

logger = logging.getLogger(__name__)


class PrivacyLeakDetector:
    """è€å¹´äººéšç§ä¿æŠ¤æ£€æµ‹æœåŠ¡"""
    
    def __init__(self, openai_api_key: str, model_name: str = "qwen-vl-max-2025-04-08"):  # é»˜è®¤ä½¿ç”¨Qwen-VLæ¨¡å‹
        dashscope.api_key = openai_api_key
        self.model_name = model_name
        

        
        # éšç§ä¿æŠ¤çš„ç³»ç»Ÿæç¤ºè¯
        # ä»app/prompts/privacy_protection_prompt.txtä¸­è¯»å–
        try:
            with open('app/prompts/privacy_protection_prompt.txt', 'r', encoding='utf-8') as file:
                self.system_prompt = file.read()
        except FileNotFoundError:
            # å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶ï¼Œä½¿ç”¨ç›¸å¯¹äºå½“å‰æ–‡ä»¶çš„è·¯å¾„
            import os
            current_dir = os.path.dirname(__file__)
            prompt_path = os.path.join(os.path.dirname(current_dir), 'prompts', 'privacy_protection_prompt.txt')
            with open(prompt_path, 'r', encoding='utf-8') as file:
                self.system_prompt = file.read()
    
    def update_prompt_config(self, parent_json: Dict[str, Any], child_json: Dict[str, Any]):
        """æ›´æ–°ç³»ç»Ÿæç¤ºè¯é…ç½®"""
        try:
            # é‡æ–°è¯»å–åŸå§‹promptæ–‡ä»¶ï¼Œç¡®ä¿æœ‰æœ€æ–°çš„åŸºç¡€prompt
            try:
                with open('app/prompts/privacy_protection_prompt.txt', 'r', encoding='utf-8') as file:
                    base_prompt = file.read()
            except FileNotFoundError:
                import os
                current_dir = os.path.dirname(__file__)
                prompt_path = os.path.join(os.path.dirname(current_dir), 'prompts', 'privacy_protection_prompt.txt')
                with open(prompt_path, 'r', encoding='utf-8') as file:
                    base_prompt = file.read()
            
            # å®šä¹‰æ ‡å‡†çš„éšç§ä¿¡æ¯ç±»åˆ«æ˜ å°„
            standard_categories = {
                "æ ¸å¿ƒèº«ä»½ä¸è´¢åŠ¡ä¿¡æ¯": ["æ ¸å¿ƒèº«ä»½", "è´¢åŠ¡ä¿¡æ¯", "é“¶è¡Œå¡", "å¯†ç ", "ç¤¾ä¿å·", "æ ¸å¿ƒèº«ä»½ä¸è´¢åŠ¡ä¿¡æ¯"],
                "ä¸ªäººæ ‡è¯†ä¸å®‰å…¨éªŒè¯ä¿¡æ¯": ["ä¸ªäººæ ‡è¯†", "å®‰å…¨éªŒè¯", "å‡ºç”Ÿæ—¥æœŸ", "ä½å€", "ç”µè¯", "ä¸ªäººæ ‡è¯†ä¸å®‰å…¨éªŒè¯ä¿¡æ¯"],
                "å®æ—¶ä½ç½®ä¸æ—¥å¸¸è¡Œè¸ª": ["å®æ—¶ä½ç½®", "æ—¥å¸¸è¡Œè¸ª", "å®šä½", "è¡Œç¨‹", "GPS", "å®æ—¶ä½ç½®ä¸æ—¥å¸¸è¡Œè¸ª"],
                "ä¸ªäººç”Ÿæ´»ä¸å®¶åº­å…³ç³»": ["ä¸ªäººç”Ÿæ´»", "å®¶åº­å…³ç³»", "å®¶åº­ä¿¡æ¯", "å¥åº·çŠ¶å†µ", "ä¸ªäººç”Ÿæ´»ä¸å®¶åº­å…³ç³»"]
            }
            
            # å°†è¾“å…¥çš„ç±»åˆ«æ˜ å°„åˆ°æ ‡å‡†ç±»åˆ«
            mapped_scores = {}
            all_input_categories = set(parent_json.keys()) | set(child_json.keys())
            
            for input_category in all_input_categories:
                parent_score = parent_json.get(input_category, 0)
                child_score = child_json.get(input_category, 0)
                combined_score = (parent_score + child_score) / 2
                
                # æ‰¾åˆ°åŒ¹é…çš„æ ‡å‡†ç±»åˆ«
                matched = False
                for standard_cat, aliases in standard_categories.items():
                    if any(alias in input_category for alias in aliases) or input_category in aliases:
                        mapped_scores[standard_cat] = max(mapped_scores.get(standard_cat, 0), combined_score)
                        matched = True
                        break
                
                # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ ‡å‡†ç±»åˆ«ï¼Œç›´æ¥ä½¿ç”¨åŸç±»åˆ«å
                if not matched:
                    mapped_scores[input_category] = combined_score
            
            # æ ¹æ®è¯„åˆ†ç”Ÿæˆpromptè°ƒæ•´å†…å®¹
            if mapped_scores:
                base_prompt += "\n\n## ğŸ¯ éšç§ä¿æŠ¤æ£€æµ‹å…³æ³¨åº¦é…ç½®\n"
                base_prompt += "è¯·æ ¹æ®ä»¥ä¸‹å„ç±»éšç§ä¿¡æ¯çš„å…³æ³¨ç¨‹åº¦è°ƒæ•´æ£€æµ‹ä¸¥æ ¼åº¦ï¼š\n"
                
                # æŒ‰åˆ†æ•°æ’åºï¼Œé«˜åˆ†çš„ä¼˜å…ˆå…³æ³¨
                sorted_categories = sorted(mapped_scores.items(), key=lambda x: x[1], reverse=True)
                
                high_priority = []  # 4-5åˆ†
                medium_priority = []  # 2-3åˆ†
                low_priority = []  # 0-1åˆ†
                
                for category, score in sorted_categories:
                    if score >= 4:
                        high_priority.append(f"{category}({score:.1f}åˆ†)")
                    elif score >= 2:
                        medium_priority.append(f"{category}({score:.1f}åˆ†)")
                    else:
                        low_priority.append(f"{category}({score:.1f}åˆ†)")
                
                if high_priority:
                    base_prompt += f"\n**ğŸš¨ é«˜åº¦å…³æ³¨ç±»åˆ«ï¼ˆä¸¥æ ¼ä¿æŠ¤ï¼‰**: {', '.join(high_priority)}"
                    base_prompt += "\n- å¯¹è¿™äº›ç±»åˆ«çš„éšç§ä¿¡æ¯è¦æåº¦æ•æ„Ÿï¼Œå³ä½¿é—´æ¥æš´éœ²ä¹Ÿè¦è­¦å‘Šå¹¶æä¾›ä¿æŠ¤å»ºè®®"
                    base_prompt += "\n- åœ¨privacy_categoryå­—æ®µä¸­ä¼˜å…ˆè¯†åˆ«è¿™äº›ç±»åˆ«"
                    base_prompt += "\n- é£é™©ç­‰çº§è‡ªåŠ¨æå‡åˆ°'é«˜é£é™©'æˆ–'æé«˜é£é™©'"
                
                if medium_priority:
                    base_prompt += f"\n**âš ï¸ ä¸­åº¦å…³æ³¨ç±»åˆ«ï¼ˆå¸¸è§„ä¿æŠ¤ï¼‰**: {', '.join(medium_priority)}"
                    base_prompt += "\n- å¯¹è¿™äº›ç±»åˆ«ä¿æŒæ­£å¸¸çš„éšç§ä¿æŠ¤æ ‡å‡†"
                
                if low_priority:
                    base_prompt += f"\n**ğŸ“ ä½åº¦å…³æ³¨ç±»åˆ«ï¼ˆåŸºç¡€ä¿æŠ¤ï¼‰**: {', '.join(low_priority)}"
                    base_prompt += "\n- å¯¹è¿™äº›ç±»åˆ«è¿›è¡ŒåŸºç¡€çš„éšç§æ£€æŸ¥ï¼Œæ ‡è®°æ˜æ˜¾çš„éšç§é£é™©"
                
                base_prompt += "\n\n**é‡è¦**: åœ¨è¿”å›çš„JSONä¸­ï¼Œprivacy_categoryå­—æ®µå¿…é¡»ä½¿ç”¨ä»¥ä¸‹æ ‡å‡†ç±»åˆ«åç§°ä¹‹ä¸€ï¼š"
                base_prompt += "\n- æ ¸å¿ƒèº«ä»½ä¸è´¢åŠ¡ä¿¡æ¯"
                base_prompt += "\n- ä¸ªäººæ ‡è¯†ä¸å®‰å…¨éªŒè¯ä¿¡æ¯"
                base_prompt += "\n- å®æ—¶ä½ç½®ä¸æ—¥å¸¸è¡Œè¸ª"
                base_prompt += "\n- ä¸ªäººç”Ÿæ´»ä¸å®¶åº­å…³ç³»"
                base_prompt += "\n\n**ä¸¥æ ¼è¦æ±‚**: ä¸å…è®¸ä½¿ç”¨'å…¶ä»–'ç±»åˆ«ï¼Œå¿…é¡»å‡†ç¡®å½’ç±»åˆ°ä¸Šè¿°å››ä¸ªæ ‡å‡†ç±»åˆ«ä¸­çš„ä¸€ä¸ªã€‚"
                base_prompt += "\n\n**è¯ˆéª—åœºæ™¯æé†’**: è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹å¯èƒ½çš„è¯ˆéª—åˆ©ç”¨åœºæ™¯ï¼š"
                base_prompt += "\n- èº«ä»½å†’ç”¨å’Œé‡‘èè¯ˆéª—ï¼ˆæ ¸å¿ƒèº«ä»½ä¸è´¢åŠ¡ä¿¡æ¯ï¼‰"
                base_prompt += "\n- ç²¾å‡†è¯ˆéª—å’Œå¯†ç é‡ç½®æ”»å‡»ï¼ˆä¸ªäººæ ‡è¯†ä¸å®‰å…¨éªŒè¯ä¿¡æ¯ï¼‰"
                base_prompt += "\n- å…¥å®¤ç›—çªƒå’Œäººèº«å®‰å…¨å¨èƒï¼ˆå®æ—¶ä½ç½®ä¸æ—¥å¸¸è¡Œè¸ªï¼‰"
                base_prompt += "\n- äº²å‹æ±‚åŠ©è¯ˆéª—å’ŒåŒ»ç–—æ•‘åŠ©è¯ˆéª—ï¼ˆä¸ªäººç”Ÿæ´»ä¸å®¶åº­å…³ç³»ï¼‰"
                base_prompt += "\n\nè¯·åœ¨æ£€æµ‹æ—¶å‚è€ƒä»¥ä¸Šå…³æ³¨åº¦è®¾ç½®ï¼Œå¯¹é«˜å…³æ³¨åº¦ç±»åˆ«æä¾›æ›´è¯¦ç»†çš„éšç§ä¿æŠ¤å»ºè®®ã€‚"
            
            # æ›´æ–°ç³»ç»Ÿæç¤ºè¯
            self.system_prompt = base_prompt
            logger.info(f"éšç§æ³„éœ²æ£€æµ‹å™¨çš„ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°ï¼Œå¤„ç†äº†{len(mapped_scores)}ä¸ªç±»åˆ«")
            
        except Exception as e:
            logger.error(f"æ›´æ–°éšç§æ³„éœ²æ£€æµ‹å™¨æç¤ºè¯å¤±è´¥: {e}")
            raise
    
    async def detect_privacy_leak(
        self, 
        content: str, 
        user_id: Optional[str] = None,
        images: Optional[List[str]] = None
    ) -> PrivacyLeakDetectionResult:
        """æ£€æµ‹éšç§æ³„éœ²é£é™©ï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼šæ–‡æœ¬+å›¾åƒï¼‰"""
        max_tries = 3
        last_error = None
        
        for attempt in range(max_tries):
            try:
                logger.info(f"éšç§ä¿æŠ¤æ£€æµ‹å°è¯• {attempt + 1}/{max_tries}")
                
                # ä½¿ç”¨LLMè¿›è¡Œè¯¦ç»†åˆ†æï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰
                analysis_result = await self._analyze_content_with_llm_multimodal(
                    content, images
                )
                
                # å…¼å®¹æ–°æ—§å­—æ®µ
                has_risk = analysis_result.get("has_privacy_risk", analysis_result.get("has_privacy_leak", False))
                
                # å¤„ç† evidence å­—æ®µ - å°†å­—å…¸åˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²åˆ—è¡¨
                risky_info = analysis_result.get("risky_information", [])
                evidence_strings = []
                if isinstance(risky_info, list):
                    for item in risky_info:
                        if isinstance(item, dict):
                            # å°†å­—å…¸è½¬æ¢ä¸ºæè¿°æ€§å­—ç¬¦ä¸²
                            risk_type = item.get("type", "æœªçŸ¥ç±»å‹")
                            content = item.get("content", "")
                            explanation = item.get("risk_explanation", "")
                            evidence_strings.append(f"{risk_type}: {content} - {explanation}")
                        else:
                            evidence_strings.append(str(item))
                
                return PrivacyLeakDetectionResult(
                    result_id=self._generate_result_id(),
                    content_text=content,
                    is_detected=has_risk,
                    confidence_score=analysis_result.get("confidence", 0.0),
                    reasons=analysis_result.get("privacy_risks", analysis_result.get("reasons", [])),
                    evidence=evidence_strings,  # ä½¿ç”¨è½¬æ¢åçš„å­—ç¬¦ä¸²åˆ—è¡¨
                    user_id=user_id,
                    privacy_types=analysis_result.get("privacy_risks", []),
                    sensitive_entities=analysis_result.get("risky_information", []),
                    risk_level=analysis_result.get("risk_level", "low"),
                    
                    # æ–°å¢çš„è€å¹´äººä¸“ç”¨å­—æ®µ
                    has_privacy_risk=has_risk,
                    privacy_risks=analysis_result.get("privacy_risks", []),
                    risky_information=analysis_result.get("risky_information", []),
                    safe_version=analysis_result.get("safe_version", ""),
                    elderly_explanation=analysis_result.get("elderly_explanation", ""),
                    protection_tips=analysis_result.get("protection_tips", []),
                    suggested_changes=analysis_result.get("suggested_changes", []),
                    privacy_category=analysis_result.get("privacy_category", "å…¶ä»–")
                )
                
            except Exception as e:
                last_error = e
                logger.warning(f"éšç§ä¿æŠ¤æ£€æµ‹ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥: {e}")
                if attempt < max_tries - 1:
                    await asyncio.sleep(1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•
                    
        # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥
        logger.error(f"éšç§ä¿æŠ¤æ£€æµ‹å¤±è´¥ï¼Œå·²å°è¯•{max_tries}æ¬¡: {last_error}")
        return self._create_error_result(content, user_id, str(last_error))


    async def _analyze_content_with_llm_multimodal(
        self, 
        content: str, 
        images: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """ä½¿ç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹åˆ†æå†…å®¹"""
        try:
            # é™åˆ¶æ–‡æœ¬å†…å®¹é•¿åº¦
            if len(content) > 2000:
                content = content[:2000] + "..."
            
            user_prompt = f"è¯·å¸®è¿™ä½è€å¹´æœ‹å‹æ£€æŸ¥ä¸€ä¸‹å³å°†å‘é€çš„å†…å®¹æ˜¯å¦å®‰å…¨ï¼š\n\nè¦å‘é€çš„å†…å®¹ï¼š\n{content}"
            
            # å¦‚æœæœ‰å›¾åƒï¼Œæ·»åŠ è¯´æ˜
            if images and len(images) > 0:
                user_prompt += f"\n\nå›¾åƒæ•°é‡ï¼š{len(images)}å¼ ï¼Œè¯·ä¸€èµ·æ£€æŸ¥å›¾ç‰‡ä¸­æ˜¯å¦æœ‰éšç§ä¿¡æ¯"
            
            user_prompt += "\n\nè¯·ä»”ç»†æ£€æŸ¥å¹¶ç»™å‡ºå®‰å…¨å»ºè®®ã€‚"
            
            # æ„å»ºmessages
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            # å‡†å¤‡å›¾åƒæ•°æ®
            image_urls = []
            if images:
                image_count = min(len(images), 5)
                for i, image_path in enumerate(images[:image_count]):
                    try:
                        with open(image_path, "rb") as image_file:
                            base64_image = base64.b64encode(image_file.read()).decode('utf-8')
                            image_urls.append(f"data:image/jpeg;base64,{base64_image}")
                    except Exception as e:
                        logger.warning(f"æ— æ³•è¯»å–å›¾åƒ {image_path}: {e}")
            
            # è°ƒç”¨Qwen-VL API
            response = await asyncio.to_thread(
                dashscope.MultiModalConversation.call,
                model=self.model_name,
                messages=messages,
                images=image_urls if image_urls else None,
                temperature=0.1,
                max_tokens=1500
            )
            
            if response.status_code != 200:
                if "API" in str(response.message):
                    print("Current API key invalid: ", dashscope.api_key)
                raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.message}")
            
            # ä¿®å¤ï¼šå¤„ç†contentå¯èƒ½æ˜¯listçš„æƒ…å†µ
            content_raw = response.output.choices[0].message.content
            if isinstance(content_raw, list):
                # å¦‚æœæ˜¯listï¼Œåˆå¹¶æ‰€æœ‰æ–‡æœ¬å†…å®¹
                result_text = ""
                for item in content_raw:
                    if isinstance(item, dict) and 'text' in item:
                        result_text += item['text']
                    elif isinstance(item, str):
                        result_text += item
                    else:
                        result_text += str(item)
            else:
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œç›´æ¥ä½¿ç”¨
                result_text = str(content_raw)
            
            result_text = result_text.strip()
            logger.debug(f"LLMåŸå§‹è¿”å›: {result_text}")
            
            # å°è¯•è§£æJSONç»“æœ
            try:
                json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
                if json_match:
                    result_json = json.loads(json_match.group())
                else:
                    result_json = json.loads(result_text)
                
                return result_json
                
            except json.JSONDecodeError:
                logger.warning(f"LLMè¿”å›ç»“æœä¸æ˜¯æœ‰æ•ˆJSON: {result_text}")
                return self._get_default_llm_result()
                
        except Exception as e:
            logger.error(f"å¤šæ¨¡æ€LLMåˆ†æå¤±è´¥: {e}")
            return self._get_default_llm_result()
    

    
    def _get_default_llm_result(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤çš„LLMç»“æœ"""
        return {
            "has_privacy_risk": False,
            "confidence": 0.0,
            "risk_level": "low",
            "privacy_risks": ["ç³»ç»Ÿæ— æ³•æ­£å¸¸åˆ†æå†…å®¹"],
            "risky_information": [],
            "safe_version": "å†…å®¹çš„å®‰å…¨æ€§æš‚æ—¶æ— æ³•ç¡®å®š",
            "elderly_explanation": "æŠ±æ­‰ï¼Œç³»ç»Ÿæš‚æ—¶æ— æ³•åˆ†æè¿™æ®µå†…å®¹çš„éšç§é£é™©ï¼Œå»ºè®®æ‚¨è°¨æ…å‘é€ï¼Œæˆ–è€…å’¨è¯¢å®¶äººæœ‹å‹çš„æ„è§ã€‚",
            "protection_tips": ["å‘é€ä¸ªäººä¿¡æ¯å‰ï¼Œå…ˆæƒ³æƒ³æ˜¯å¦çœŸçš„æœ‰å¿…è¦", "é‡è¦ä¿¡æ¯æœ€å¥½å½“é¢æˆ–ç”µè¯æ²Ÿé€š", "ä¸ç¡®å®šçš„æ—¶å€™å¯ä»¥é—®é—®å­å¥³"],
            "suggested_changes": []
        }
    
    def _generate_result_id(self) -> str:
        """ç”Ÿæˆç»“æœID"""
        return f"privacy_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
    
    def _create_error_result(self, content: str, user_id: Optional[str], 
                            error_msg: str) -> PrivacyLeakDetectionResult:
        """åˆ›å»ºé”™è¯¯ç»“æœ"""
        return PrivacyLeakDetectionResult(
            result_id=self._generate_result_id(),
            content_text=content,
            is_detected=False,
            confidence_score=0.0,
            reasons=[f"æ£€æµ‹å¤±è´¥: {error_msg}"],
            evidence=[f"ç³»ç»Ÿé”™è¯¯: {error_msg}"],  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
            user_id=user_id,
            privacy_types=[],
            sensitive_entities=[],
            risk_level="low",
            
            # æ–°å¢å­—æ®µ
            has_privacy_risk=False,
            privacy_risks=[f"æ£€æµ‹å¤±è´¥: {error_msg}"],
            risky_information=[],
            safe_version="ç”±äºç³»ç»Ÿé”™è¯¯ï¼Œæ— æ³•æä¾›å®‰å…¨å»ºè®®",
            elderly_explanation="ç³»ç»Ÿé‡åˆ°äº†æŠ€æœ¯é—®é¢˜ï¼Œæ— æ³•å®Œæˆéšç§æ£€æŸ¥ã€‚å»ºè®®æ‚¨æš‚æ—¶ä¸è¦å‘é€ï¼Œæˆ–è€…å’¨è¯¢å®¶äººçš„æ„è§ã€‚",
            protection_tips=["é‡åˆ°æŠ€æœ¯é—®é¢˜æ—¶ï¼Œè°¨æ…ä¸ºä¸Š", "é‡è¦ä¿¡æ¯å»ºè®®å½“é¢æˆ–ç”µè¯æ²Ÿé€š"],
            suggested_changes=[]
        )

if __name__ == "__main__":
    # é…ç½®æ—¥å¿—è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
    import logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('privacy_test.log', encoding='utf-8'),  # è¾“å‡ºåˆ°æ–‡ä»¶
            logging.StreamHandler()  # è¾“å‡ºåˆ°æ§åˆ¶å°
        ]
    )
    
    import asyncio
    
    async def test_detector():
        import os
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            print("é”™è¯¯: æœªè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
            print("è¯·è®¾ç½®ç¯å¢ƒå˜é‡åå†è¿è¡Œæµ‹è¯•")
            return
        detector = PrivacyLeakDetector(openai_api_key)
        
        # æµ‹è¯•å¤šä¸ªä¸åŒç±»å‹çš„å†…å®¹ï¼Œæ¨¡æ‹Ÿè€å¹´äººå¯èƒ½è¦å‘é€çš„å„ç§ä¿¡æ¯
        test_cases = [
            "æˆ‘ä½åœ¨åŒ—äº¬å¸‚æœé˜³åŒºå»ºå›½è·¯123å·ï¼Œæ‰‹æœºå·æ˜¯13812345678ï¼Œæœ‰ç©ºæ¥æ‰¾æˆ‘ç©ï¼",  # æ˜æ˜¾éšç§æ³„éœ²
            "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œæˆ‘åœ¨å…¬å›­é‡Œæ•£æ­¥ï¼Œå¿ƒæƒ…å¾ˆå¥½ã€‚",  # å®‰å…¨å†…å®¹
            "æˆ‘çš„é“¶è¡Œå¡å·æ˜¯6225123456789012ï¼Œå¯†ç æ˜¯123456ï¼Œå¸®æˆ‘è½¬è´¦å§ã€‚",  # ä¸¥é‡è´¢åŠ¡ä¿¡æ¯æ³„éœ²
            "æˆ‘å„¿å­åœ¨è…¾è®¯å…¬å¸ä¸Šç­ï¼Œå·¥èµ„å¾ˆé«˜ï¼Œæˆ‘ä»¬å®¶å¾ˆæœ‰é’±ã€‚",  # å®¶åº­ä¿¡æ¯æ³„éœ²
            "æˆ‘çš„èº«ä»½è¯å·æ˜¯110101195001011234ï¼Œå¯ä»¥å¸®æˆ‘è®¢ç¥¨å—ï¼Ÿ",  # èº«ä»½ä¿¡æ¯æ³„éœ²
            "æ˜¨å¤©å»åŒ»é™¢æ£€æŸ¥ï¼ŒåŒ»ç”Ÿè¯´æˆ‘èº«ä½“è¿˜ä¸é”™ï¼Œå­å¥³ä»¬éƒ½å¾ˆå­é¡ºã€‚",  # ç›¸å¯¹å®‰å…¨çš„åˆ†äº«
            "æˆ‘çš„QQå·æ˜¯123456789ï¼Œå¾®ä¿¡å·æ˜¯wanglaoshiï¼Œå¿«åŠ æˆ‘å¥½å‹ï¼",  # ç¤¾äº¤è´¦å·æ³„éœ²
            "æ˜å¤©ä¸Šåˆ10ç‚¹æˆ‘è¦å»é“¶è¡Œå–é’±ï¼Œä¸‹åˆ2ç‚¹å»è¶…å¸‚ä¹°èœã€‚"  # è¡Œç¨‹ä¿¡æ¯æ³„éœ²
        ]
        
        for i, test_content in enumerate(test_cases, 1):
            print(f"\n{'='*70}")
            print(f"æµ‹è¯•æ¡ˆä¾‹ {i}: {test_content}")
            print('='*70)
            
            result = await detector.detect_privacy_leak(test_content)
            
            print(f"ğŸ“ è¦å‘é€çš„å†…å®¹: {test_content}")
            print(f"ğŸ”’ æ˜¯å¦æœ‰éšç§é£é™©: {'æœ‰é£é™©' if result.is_detected else 'å®‰å…¨'}")
            print(f"ğŸ¯ é£é™©ç¨‹åº¦: {result.confidence_score:.1%}")
            print(f"âš ï¸  é£é™©ç­‰çº§: {result.risk_level}")
            
            if result.is_detected:
                print(f"\nğŸš¨ éšç§é£é™©ç±»å‹:")
                for risk in result.privacy_risks or []:
                    print(f"   â€¢ {risk}")
                
                if result.risky_information:
                    print(f"\nğŸ” å…·ä½“é£é™©ä¿¡æ¯:")
                    for info in result.risky_information:
                        print(f"   â€¢ {info.get('type', 'æœªçŸ¥')}: {info.get('content', '')} - {info.get('risk_explanation', '')}")
                
                print(f"\nâœ… å®‰å…¨çš„æ›¿ä»£ç‰ˆæœ¬:")
                print(f"   {result.safe_version}")
                
                if result.suggested_changes:
                    print(f"\nğŸ“ å…·ä½“ä¿®æ”¹å»ºè®®:")
                    for change in result.suggested_changes:
                        print(f"   åŸæ–‡: {change.get('original', '')}")
                        print(f"   æ”¹ä¸º: {change.get('suggested', '')}")
                        print(f"   åŸå› : {change.get('reason', '')}")
                        print()
            else:
                print(f"âœ… å†…å®¹å®‰å…¨ï¼Œå¯ä»¥æ”¾å¿ƒå‘é€")
            
            print(f"\nğŸ’¬ æ¸©é¦¨æé†’:")
            print(f"   {result.elderly_explanation}")
            
            if result.protection_tips:
                print(f"\nğŸ’¡ éšç§ä¿æŠ¤å°è´´å£«:")
                for tip in result.protection_tips:
                    print(f"   â€¢ {tip}")
    
    asyncio.run(test_detector()) 